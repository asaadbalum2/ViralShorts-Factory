name: ViralShorts Factory - Auto Video Generator

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Total videos per batch (BEST goes to YouTube)'
        required: false
        default: '4'  # v7.15: Optimized for max throughput within rate limits
      test_only:
        description: 'Test mode - generate but DO NOT upload (saves quota)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'
      skip_delay:
        description: 'Skip random delay (for testing)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'false'
          - 'true'

  # DISABLED TEMPORARILY - Waiting for quota reset
  # v7.17: MAXIMUM THROUGHPUT CONFIGURATION
  # =====================================================
  # HARD LIMITS:
  #   - YouTube: 10,000 units/day รท 1,600 = 6 uploads/day MAX
  #   - Groq: 100K tokens/day รท 3,900 = 25 videos/day MAX
  #   - Dailymotion: 4 uploads/hour = 96/day (not the bottleneck)
  #
  # MAXIMUM CONFIG (v7.17):
  #   - 6 batches per day (every 4 hours)
  #   - 4 videos per batch = 24 videos/day
  #   - YouTube: 6 uploads/day (MAXIMUM!)
  #   - Dailymotion: 24 uploads/day
  #   - Groq: 93,600 tokens (93.6% of quota)
  # =====================================================
  # schedule:
  #   - cron: '0 0 * * *'   # 00:00 UTC - Midnight batch
  #   - cron: '0 4 * * *'   # 04:00 UTC - Early morning batch
  #   - cron: '0 8 * * *'   # 08:00 UTC - Morning batch
  #   - cron: '0 12 * * *'  # 12:00 UTC - Noon batch
  #   - cron: '0 16 * * *'  # 16:00 UTC - Afternoon batch
  #   - cron: '0 20 * * *'  # 20:00 UTC - Evening batch

jobs:
  generate:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Random delay for stealth (0-45 min)
        if: github.event.inputs.skip_delay != 'true'
        run: |
          DELAY=$((RANDOM % 2700))
          echo "Waiting $DELAY seconds for randomization..."
          sleep $DELAY
          echo "Starting execution at $(date -u)"

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg imagemagick fonts-dejavu-core fonts-liberation
          sudo sed -i 's/rights="none" pattern="@\*"/rights="read|write" pattern="@*"/' /etc/ImageMagick-6/policy.xml || true
          sudo sed -i 's/<policy domain="path" rights="none" pattern="@\*"/<policy domain="path" rights="read|write" pattern="@*"/' /etc/ImageMagick-6/policy.xml || true

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Check API Health
        run: |
          echo "Checking API health..."
          python api_health_check.py || true
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
          YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
          YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
          DAILYMOTION_API_KEY: ${{ secrets.DAILYMOTION_API_KEY }}
          DAILYMOTION_API_SECRET: ${{ secrets.DAILYMOTION_API_SECRET }}
          DAILYMOTION_USERNAME: ${{ secrets.DAILYMOTION_USERNAME }}
          DAILYMOTION_PASSWORD: ${{ secrets.DAILYMOTION_PASSWORD }}
        continue-on-error: true

      - name: Create asset directories
        run: |
          mkdir -p assets/backgrounds assets/broll assets/music assets/sfx assets/fonts
          mkdir -p output cache data/persistent
      
      # v9.0: Download persistent state via API (reliable cross-workflow)
      - name: Restore persistent state
        run: |
          ARTIFACT_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts?name=persistent-state&per_page=1" \
            | jq -r '.artifacts[0].id')
          
          if [ "$ARTIFACT_ID" != "null" ] && [ -n "$ARTIFACT_ID" ]; then
            curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip" \
              -o /tmp/state.zip
            unzip -o /tmp/state.zip -d data/persistent/ 2>/dev/null || true
            echo "[OK] Restored patterns from artifact $ARTIFACT_ID"
          else
            echo "[INFO] No previous state found - starting fresh"
          fi
        continue-on-error: true

      - name: Pre-fetch some B-roll (optional cache)
        run: python fetch_broll.py || true
        env:
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
        continue-on-error: true

      # ====================================================================
      # v9.0: MAXIMUM QUALITY - 25 Enhancements Active
      # - 3-Layer quality gates (pre-gen, post-content, post-render)
      # - Semantic duplicate detection
      # - Retention curve prediction
      # - A/B test tracking
      # - Error pattern learning
      # - Voice pacing intelligence
      # - YouTube: 6/day (max) | Dailymotion: 24/day (rate-aware)
      # ====================================================================
      - name: Generate Videos (v9.0 - Maximum Quality)
        run: |
          # Set defaults for scheduled runs
          BATCH="${{ github.event.inputs.batch_size }}"
          BATCH="${BATCH:-4}"  # Default to 4 for optimal throughput
          TEST_ONLY="${{ github.event.inputs.test_only }}"
          TEST_ONLY="${TEST_ONLY:-false}"
          
          echo "=============================================="
          echo "   VIRALSHORTS FACTORY v9.0"
          echo "   MAXIMUM QUALITY - 25 ENHANCEMENTS"
          echo "   Batch: $BATCH videos"
          echo "   Quality Gates: Pre-gen, Post-content, Post-render"
          echo "   YouTube: BEST video (6/day MAX)"
          echo "   Dailymotion: Rate-limit aware (4/hour)"
          echo "   Variety: Semantic duplicate detection active"
          echo "=============================================="
          
          if [ "$TEST_ONLY" = "true" ]; then
            echo "TEST MODE: Generating without uploads"
            python pro_video_generator.py --count $BATCH --no-upload
          else
            echo "PRODUCTION MODE: Generating with strategic uploads"
            # --strategic-youtube: AI picks the BEST video for YouTube
            # All videos go to Dailymotion
            python pro_video_generator.py --count $BATCH --upload --strategic-youtube
          fi
        env:
          YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
          YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
          YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          DAILYMOTION_API_KEY: ${{ secrets.DAILYMOTION_API_KEY }}
          DAILYMOTION_API_SECRET: ${{ secrets.DAILYMOTION_API_SECRET }}
          DAILYMOTION_USERNAME: ${{ secrets.DAILYMOTION_USERNAME }}
          DAILYMOTION_PASSWORD: ${{ secrets.DAILYMOTION_PASSWORD }}
          PYTHONUNBUFFERED: "1"

      - name: Save videos as artifacts (for preview)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: generated-videos
          path: output/*.mp4
          retention-days: 3
          if-no-files-found: ignore

      - name: Verify video generation
        id: verify
        run: |
          echo "Checking for generated videos..."
          VIDEO_COUNT=$(ls output/*.mp4 2>/dev/null | wc -l)
          echo "video_count=$VIDEO_COUNT" >> $GITHUB_OUTPUT
          
          if [ "$VIDEO_COUNT" -eq 0 ]; then
            echo "CRITICAL: No videos were generated!"
            echo "::error::VIDEO GENERATION FAILED - Check logs above for errors"
            exit 1
          else
            echo ""
            echo "Generated $VIDEO_COUNT video(s)"
            for f in output/*.mp4; do
              if [ -f "$f" ]; then
                SIZE=$(stat --printf="%s" "$f" 2>/dev/null || stat -f%z "$f" 2>/dev/null)
                SIZE_MB=$((SIZE / 1024 / 1024))
                echo "   - $f (${SIZE_MB}MB)"
                ffprobe -v quiet -show_format -show_streams "$f" 2>/dev/null | grep -E "(duration|width|height|bit_rate)" || true
              fi
            done
          fi

      - name: Collect Analytics (Learn from past performance)
        if: github.event.inputs.test_only != 'true'
        continue-on-error: true
        run: |
          echo "Collecting analytics data..."
          python -c "
          import os
          from analytics_feedback import FeedbackLoopController

          try:
              controller = FeedbackLoopController()
              
              # Fetch latest performance data
              updated = controller.update_all_performance()
              print(f'Updated performance for {updated} videos')
              
              # Run analysis if we have enough data
              all_videos = controller.metadata_store.get_all()
              if len([v for v in all_videos if v.performance]) >= 5:
                  print('Running AI analysis...')
                  insights = controller.run_analysis()
                  if insights.get('key_insight'):
                      print(f'Key Insight: {insights[\"key_insight\"]}')
              else:
                  print('Not enough data for analysis yet (need 5+ videos with views)')
                  
          except Exception as e:
              print(f'Analytics error: {e}')
          "
        env:
          YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
          YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
          YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}

      # v8.0: Save persistent state for next run
      - name: Save persistent state
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: persistent-state
          path: data/persistent/
          retention-days: 30
          if-no-files-found: ignore
          overwrite: true

      - name: Summary
        run: |
          echo "## ViralShorts Factory v9.0 - MAXIMUM QUALITY" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "**Batch Size:** ${{ github.event.inputs.batch_size || '4' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Test Mode:** ${{ github.event.inputs.test_only || 'false' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### v9.0 ENHANCEMENTS (25 Total!)" >> $GITHUB_STEP_SUMMARY
          echo "- **3-Layer Quality Gates**: Pre-gen, post-content, post-render validation" >> $GITHUB_STEP_SUMMARY
          echo "- **Semantic Duplicate Detection**: AI checks for similar recent topics" >> $GITHUB_STEP_SUMMARY
          echo "- **Retention Curve Prediction**: AI predicts where viewers drop off" >> $GITHUB_STEP_SUMMARY
          echo "- **A/B Test Tracking**: Learns which title styles perform best" >> $GITHUB_STEP_SUMMARY
          echo "- **Error Pattern Learning**: Learns from B-roll failures" >> $GITHUB_STEP_SUMMARY
          echo "- **Voice Pacing Intelligence**: Optimal pacing per phrase" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Weekly Analytics (Sundays)" >> $GITHUB_STEP_SUMMARY
          echo "- Comment mining for insights" >> $GITHUB_STEP_SUMMARY
          echo "- Shadow-ban detection" >> $GITHUB_STEP_SUMMARY
          echo "- Performance pattern analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Monthly Analysis (1st of month)" >> $GITHUB_STEP_SUMMARY
          echo "- Competitor tracking" >> $GITHUB_STEP_SUMMARY
          echo "- Content recycling suggestions" >> $GITHUB_STEP_SUMMARY
          echo "- Viral pattern extraction" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Daily Output" >> $GITHUB_STEP_SUMMARY
          echo "- **YouTube: 6 uploads/day (MAXIMUM!)**" >> $GITHUB_STEP_SUMMARY
          echo "- **Dailymotion: 24 uploads/day (rate-limit aware)**" >> $GITHUB_STEP_SUMMARY
          echo "- Schedule: Every 4 hours (6 runs/day)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Channels" >> $GITHUB_STEP_SUMMARY
          echo "- YouTube: https://www.youtube.com/channel/UC4Y6O0ubwl0_ZQsLq2EteTQ" >> $GITHUB_STEP_SUMMARY
          echo "- Dailymotion: https://www.dailymotion.com/ViralShorts-Factory" >> $GITHUB_STEP_SUMMARY
